{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dfee73",
   "metadata": {},
   "source": [
    "# GANs Image Generation\n",
    "\n",
    "In this notebook, we will explore how Generative Adversarial Networks (GANs) generate images. We will use a pretrained GAN model (BigGAN) to generate images from random noise.\n",
    "\n",
    "## Instructions\n",
    "1. Run the code below to generate an image from random noise.\n",
    "2. Modify the latent vector to generate different images.\n",
    "3. Experiment with generating different images by altering the latent vector and visualizing the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1448e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BigGAN.forward() missing 2 required positional arguments: 'class_label' and 'truncation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Generate image\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 14\u001b[0m     generated_image \u001b[38;5;241m=\u001b[39m model(latent_vector)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Convert the tensor to a displayable image\u001b[39;00m\n\u001b[1;32m     17\u001b[0m generated_image \u001b[38;5;241m=\u001b[39m generated_image\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: BigGAN.forward() missing 2 required positional arguments: 'class_label' and 'truncation'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_biggan import BigGAN\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load pretrained BigGAN model\n",
    "model = BigGAN.from_pretrained('biggan-deep-256')\n",
    "\n",
    "# Generate random latent vector (noise)\n",
    "latent_vector = torch.randn(1, 128)  # 128 is the size of the input vector for BigGAN\n",
    "\n",
    "# Generate image\n",
    "with torch.no_grad():\n",
    "    generated_image = model(latent_vector)\n",
    "\n",
    "# Convert the tensor to a displayable image\n",
    "generated_image = generated_image.squeeze().cpu().numpy()\n",
    "generated_image = (generated_image * 255).astype('uint8')\n",
    "Image.fromarray(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0053511",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experiment with different latent vectors\n",
    "latent_vector = torch.randn(1, 128)  # Change this to explore different random vectors\n",
    "with torch.no_grad():\n",
    "    generated_image = model(latent_vector)\n",
    "generated_image = generated_image.squeeze().cpu().numpy()\n",
    "generated_image = (generated_image * 255).astype('uint8')\n",
    "Image.fromarray(generated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff7b1ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Reflection\n",
    "\n",
    "Now that you have generated images, write a brief report reflecting on your observations:\n",
    "\n",
    "1. How did the generated images change when you modified the latent vector?\n",
    "2. What patterns did you notice in the generated images? Were they realistic?\n",
    "3. How does the process of generating images from noise differ from traditional image generation methods?\n",
    "4. What challenges or limitations did you observe with the GAN model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
